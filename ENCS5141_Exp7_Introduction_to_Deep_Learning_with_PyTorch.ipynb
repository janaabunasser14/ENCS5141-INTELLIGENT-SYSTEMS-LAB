{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnwN99fLeip7lTo42F29JK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janaabunasser14/ENCS5141-INTELLIGENT-SYSTEMS-LAB/blob/main/ENCS5141_Exp7_Introduction_to_Deep_Learning_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z7yMMoZRJRht"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Initialization"
      ],
      "metadata": {
        "id": "F3BV5h17Jlas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "-Jel89BkJmPt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "Xps3L_QbJqiM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCydjmpAJteF",
        "outputId": "e0a533ae-ffe8-4a06-8dab-10dea8c968de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.5892, 0.3233],\n",
            "        [0.9715, 0.1850]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2, 3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHNKP6FRJ3nk",
        "outputId": "f33736da-11e0-4582-cee5-fcb589b161e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.9433, 0.5349, 0.2244],\n",
            "        [0.7923, 0.7921, 0.6560]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Attributes"
      ],
      "metadata": {
        "id": "t3X8epsyJ9rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3, 4)\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgHYuyToJ-V1",
        "outputId": "1f22c74b-0bea-462c-ac67-ea7ac038f216"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Operations"
      ],
      "metadata": {
        "id": "CW-yEjGCKJJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "id": "PVkhf4VFKJhF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR3VCZdJKPGE",
        "outputId": "b9c782e7-c36e-4174-b5b6-afa08426ba78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oE7Tl9DKRU0",
        "outputId": "1253d274-972d-4647-fd7f-51161cf047b5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the element-wise product\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEkB4mVvKTpc",
        "outputId": "2672f88c-7d93-42eb-d2f1-646ffdbfea5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.mul(tensor) \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy_2J_1DKWOs",
        "outputId": "986653c2-ea84-4d92-8c35-142a7bf97d70"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.matmul(tensor.T) \n",
            " tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]]) \n",
            "\n",
            "tensor @ tensor.T \n",
            " tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDX25scXKYUF",
        "outputId": "5bd5995e-4cea-4dd3-cf86-8b1cb4608f1c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bridge with NumPy"
      ],
      "metadata": {
        "id": "7ze6RMF8KbFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")\n",
        "\n",
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a30CMKjqKbu1",
        "outputId": "9ba5be5b-fa6b-4dec-d0a7-540f9e08589f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n",
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)\n",
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_Pu2PuVKgXF",
        "outputId": "6d81a79e-e5ce-4a0b-d508-e29d22492962"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Differentiation in Autograd"
      ],
      "metadata": {
        "id": "ogHiiKZrKktM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)"
      ],
      "metadata": {
        "id": "0m0s_IbRKke-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q = 3*a**3 - b**2"
      ],
      "metadata": {
        "id": "Mt9IrIguKqHF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if collected gradients are correct\n",
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF3wGH12Kvt7",
        "outputId": "ef8d5d7d-ae27-4499-b1a3-9775c5c63bac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1"
      ],
      "metadata": {
        "id": "q6kndIBeLKLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# point x1, x2 (1, 1)\n",
        "x1 = torch.tensor(1., requires_grad=True)\n",
        "x2 = torch.tensor(1., requires_grad=True)"
      ],
      "metadata": {
        "id": "lBJ4BhFmLKkU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q = (3*x1 - 2*x2 - 2) ** 2"
      ],
      "metadata": {
        "id": "xtP5jvZKLOrF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "external_grad = torch.tensor(1.)\n",
        "Q.backward(gradient=external_grad)"
      ],
      "metadata": {
        "id": "VfNLkdBeLQWM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if collected gradients are correct\n",
        "# Manually differenatiated\n",
        "dx1 = 2 * (3*x1 - 2*x2 - 2) * (3)\n",
        "dx2 = 2 * (3*x1 - 2*x2 - 2) * (-2)\n",
        "\n",
        "print(dx1 == x1.grad)\n",
        "print(dx2 == x2.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeS7QVJHLT-E",
        "outputId": "42ad7e36-f8ab-4e39-ec1e-a9c1abf1e2e8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(True)\n",
            "tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the network"
      ],
      "metadata": {
        "id": "LUbyDZD-LQ7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    # an affine operation: y = Wx + b\n",
        "    # 784 is the input dimension, and 68 is the output dimenstion of the first hidden layer\n",
        "    self.fc1 = nn.Linear(784, 64)\n",
        "    self.fc2 = nn.Linear(64, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # apply the first layer with relu activation\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzsegdkrLW2U",
        "outputId": "d08f93cd-e3a0-4189-8dbf-83e5db1a4300"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "\n",
        "for p in params:\n",
        "  print(p.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLb-M0SoLcSM",
        "outputId": "71a967cf-70bc-4b0f-a1f3-40c09e939ed4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "torch.Size([64, 784])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 64])\n",
            "torch.Size([64])\n",
            "torch.Size([10, 64])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Identify what are the parameters that are printed in the previous code"
      ],
      "metadata": {
        "id": "-FXVQwooLiIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.Size([64, 784]): This represents the weight matrix for the first layer of the neural network. It has a size of 64 (output features) by 784 (input features).\n",
        "\n",
        "torch.Size([64]): This represents the bias vector for the first layer. It has a size of 64, corresponding to the number of output features in the first layer.\n",
        "\n",
        "torch.Size([64, 64]): This represents the weight matrix for the second layer of the neural network. It has a size of 64 (output features) by 64 (input features).\n",
        "\n",
        "torch.Size([64]): This represents the bias vector for the second layer. It has a size of 64, corresponding to the number of output features in the second layer.\n",
        "\n",
        "torch.Size([10, 64]): This represents the weight matrix for the third (output) layer of the neural network. It has a size of 10 (output classes) by 64 (input features from the previous layer).\n",
        "\n",
        "torch.Size([10]): This represents the bias vector for the third layer. It has a size of 10, corresponding to the number of output classes in the network.\n",
        "\n"
      ],
      "metadata": {
        "id": "mYg3BTQaLjO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(1, 784)\n",
        "out = net(input)\n",
        "\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4HJdNvJLmm0",
        "outputId": "d602689d-879e-4337-9b35-48aa1ef5f47e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1032, -0.0130,  0.0800,  0.0086,  0.1499, -0.0672, -0.0532,  0.1655,\n",
            "         -0.0401, -0.0982]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3: Try the previous network with a random mini-batch of size 4 and print its output."
      ],
      "metadata": {
        "id": "NH-ajtpWLqzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(4, 784)\n",
        "out = net(input)\n",
        "\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymAfItNTLno0",
        "outputId": "931a2454-751a-46ba-946a-e154300d76af"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1046, -0.0651,  0.0638,  0.0518,  0.2444, -0.0800, -0.0390,  0.1712,\n",
            "         -0.0713, -0.0350],\n",
            "        [ 0.1547,  0.0007,  0.1070,  0.0341,  0.1684, -0.0978,  0.0178,  0.0468,\n",
            "         -0.0056, -0.1023],\n",
            "        [ 0.1282, -0.0657,  0.0964, -0.0005,  0.1582,  0.1131,  0.0791,  0.1187,\n",
            "         -0.0837, -0.0132],\n",
            "        [ 0.3379,  0.0307,  0.0415,  0.0475,  0.2194, -0.0688,  0.0675,  0.0172,\n",
            "          0.2189, -0.2463]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a Loss function and optimizer"
      ],
      "metadata": {
        "id": "m-bZyHwMLxL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Sj8XUashLx4s"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading a Dataset"
      ],
      "metadata": {
        "id": "6wzwuJhmL2M8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "training_data = datasets.MNIST(\n",
        "  root=\"data\",\n",
        "  train=True,\n",
        "  download=True,\n",
        "  transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "  root=\"data\",\n",
        "  train=False,\n",
        "  download=True,\n",
        "  transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbkEUZIGLzzE",
        "outputId": "9e091121-61e6-4982-acaf-c6f5b64d2a5e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 50789606.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1646849.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 13081159.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4025893.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iterating and Visualizing the Dataset"
      ],
      "metadata": {
        "id": "vg6rnomvL-3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "\n",
        "for i in range(1, cols * rows + 1):\n",
        "  sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "  img, label = training_data[sample_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.title(\"digit:\" + str(label))\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "amsznjbPL_PM",
        "outputId": "0fa3ba85-524c-4f89-97e1-2649705db575"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAKSCAYAAABMVtaZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBOklEQVR4nO3deVyV1b7H8d9WRAhxIBEpCkpN0SRz1hwgDczslqVlZqWlVE7ZuWXZUQEzO02nsnyZmamZNtlJr5midcCcKoc4Ws6ZmoqGU4qihD73j67czLU2PJs9r8/79Tp/+Fv8nme5Dyu/POy1tsOyLEsAAAAQ9Cr5egIAAADwDoIfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIgp+bZGZmisPhKP1zQkKC9O/f36VrJScnS3JysnsmBgQZ1hrgHay14ETwCwD79++XzMxMycvLK9fXnzp1SiZNmiSpqakSGxsrkZGRcv3118vkyZPl7Nmznp0sEMDsrjWRP/5BczgcF/2vW7dunpsoEOBcWWsiIqtWrZIOHTrIJZdcInXr1pXhw4dLYWGhZyYZpEJ8PYFgtXXrVqlUybVcvWTJkgv+vH//fsnKypKEhARp1qxZmf07d+6UYcOGSZcuXeRvf/ubVK9eXbKzs2Xw4MHyzTffyMyZM12aF+CPfLnWzouLi5Pnn3/+gtpll13m0pwAf+XrtZaXlyddunSRxMRE+ec//yl79+6Vl19+WbZv3y6LFi1yaV4mIvh5SNWqVV3uDQ0NrdC969atKxs3bpQmTZqU1h5++GF58MEHZfr06TJmzBipX79+he4B+AtfrrXzatSoIf369XPLtQB/5eu19swzz0itWrUkNzdXqlevLiJ//Pp50KBBsmTJEklNTa3wPUzAr3pdsGLFCmnVqpWEhYVJvXr1ZMqUKRd9jeq9EBs2bJDOnTtLeHi4xMXFyfjx42X69OnicDhk165dpV/35/dC5ObmSqtWrUREZMCAAaW/RpoxY4aI/PFr3S1btsihQ4dK+2vXrn1B6DuvZ8+eIiKyefPmCvztAe/x97X2ZyUlJfzKCQHL39fa8ePHZenSpdKvX7/S0Ccicv/990u1atXk448/ds8LYQCe+Nm0ceNGSU1NlejoaMnMzJSSkhLJyMiQmJgYp3379u2TlJQUcTgcMmrUKImIiJB33nmnzJ+gEhMTZdy4cTJ27FhJT0+Xjh07iohI+/btRUTku+++k5SUFMnIyJDMzEyn1zpw4ICI/BEMAX8XSGtt27ZtEhERIcXFxRITEyODBg2SsWPHSpUqVVx/AQAvCYS1tnHjRikpKZGWLVtecK3Q0FBp1qyZfP/99y7+7c1D8LNp7NixYlmWLF++XK688koREbnzzjuladOmTvteeOEFOXr0qKxfv770/QwDBgyQBg0aOO2LiYmRm2++WcaOHSvt2rVz+ddJxcXF8tprr8lVV11V+pMW4M8CZa3Vq1dPUlJSpGnTpnLy5EmZO3eujB8/XrZt2yYfffRRua4B+FIgrLX8/HwREYmNjb1oLDY2VpYvX17mNfAHgp8NZ8+elezsbLn99ttLF4fIHz+9pKWlyRdffKHtXbx4sbRr1+6CN7FGRUXJvffeK2+88YbLc0pOThbLssr8uqFDh8qmTZtk4cKFEhLC/+3wb4G01qZNm3bBn++77z5JT0+XqVOnyuOPPy5t27Z1+Z6ApwXKWisqKhIR9fsMw8LCSsdRNt7jZ0NBQYEUFRUpf5pp2LCh097du3crN1R4Y5PFSy+9JFOnTpVnn31Wunfv7vH7ARUVqGvtvP/+7/8WEZEvv/zSa/cEXBEoay08PFxERM6cOXPR2OnTp0vHUTaCX5CbMWOGPPXUU/LII4/I6NGjfT0dwAhXXHGFiIgcOXLExzMBgsP5X/Ge/5Xvn+Xn53N8kg0EPxuio6MlPDxctm/fftHY1q1bnfbGx8fLjh07Lqqran/155PT7Zg/f74MHDhQ7rjjDpk0aZJL1wB8IdDW2l/t3LlTRP74ewD+LFDW2rXXXishISGydu3aC+rFxcWSl5dn69xN0xH8bKhcubKkpaXJvHnzZM+ePaX1zZs3S3Z2ttPetLQ0Wb169QWnlB85ckRmz55d5n0jIiJEROTYsWMXjemOmPj666+lT58+0qlTJ5k9e7bLh24CvhAoa+348eMX/erJsiwZP3586VwAfxYoa61GjRrStWtXef/99+XEiROl9VmzZklhYaH07t27zHviD7zL36asrCxZvHixdOzYUQYPHiwlJSXyxhtvSJMmTWTDhg3avpEjR8r7778vN910kwwbNqx02/uVV14pR44ccfrTT7169aRmzZry1ltvSWRkpEREREibNm3kqquuUm573717t/zXf/2XOBwO6dWrl3zyyScXXC8pKUmSkpLc8noAnhIIa239+vVyzz33yD333CP169eXoqIi+eyzz2TlypWSnp4uzZs3d/fLArhdIKw1EZHnnntO2rdvL507d5b09HTZu3evvPLKK5KamspHJNphwbZly5ZZLVq0sEJDQ62rr77aeuutt6yMjAzrzy9nfHy89cADD1zQ9/3331sdO3a0qlatasXFxVnPP/+8NXHiREtErAMHDpR+XefOna3OnTtf0Dt//nyrcePGVkhIiCUi1vTp0y3LsqycnBxLRKyMjIzSrz1f0/3vz18L+DN/X2s7d+60evfubSUkJFhhYWHWJZdcYrVo0cJ66623rHPnzrn75QA8xt/X2nnLly+32rdvb4WFhVnR0dHWkCFDrOPHj7vrZTCCw7LKcRYIPGbEiBEyZcoUKSwslMqVK/t6OkDQYq0B3sFa82+88cuL/nrO0OHDh2XWrFnSoUMHFgfgRqw1wDtYa4GH9/h5Ubt27SQ5OVkSExPl4MGDMm3aNDl+/LiMGTPG11MDggprDfAO1lrgIfh5Uffu3WXu3Lny9ttvi8PhkObNm8u0adOkU6dOvp4aEFRYa4B3sNYCD+/xAwAAMATv8QMAADAEwQ8AAMAQBD8AAABDlHtzh7s+wxLwJ/74FlfWGoIRaw3wjrLWGk/8AAAADEHwAwAAMATBDwAAwBAEPwAAAEMQ/AAAAAxB8AMAADAEwQ8AAMAQBD8AAABDEPwAAAAMQfADAAAwBMEPAADAEAQ/AAAAQxD8AAAADEHwAwAAMATBDwAAwBAEPwAAAEMQ/AAAAAwR4usJBLuIiAhlPSEhQduTn5+vrB85csQdUwIAAIbiiR8AAIAhCH4AAACGIPgBAAAYguAHAABgCIIfAACAIQh+AAAAhuA4FzcICwvTjs2YMUNZ79mzp7Zn2LBhyvrkyZNtzQsAAH+Wk5OjHUtOTrZ9vdzcXGU9KyvLdk+w4okfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCHY1WuDbvfuqFGjtD3Odu/qdO/eXVm/8cYbtT07duxQ1gcMGGD7/g6HQzs2b948Zf2ZZ57R9hw+fNj2HAAAwUO3e9edO3c9cb1gxBM/AAAAQxD8AAAADEHwAwAAMATBDwAAwBAEPwAAAEMQ/AAAAAzhsCzLKtcXOjniI5hcc8012rHnnntOWXflyBZnioqKlPWff/5Z23Ps2DFl/ffff7d9f2fb4XXfLqtXr9b2dOzY0fYcvKWc3/5eZcpag1lYa8FPd2SLiP7fFWdHqaSkpNi6Vllz0Am274Oy1hpP/AAAAAxB8AMAADAEwQ8AAMAQBD8AAABDEPwAAAAMYeyu3muvvVZZd7bDqGbNmm67/wcffKAdy8zMVNYLCgq0PadOnVLWS0pKbM1LRGTUqFHasWeffVZZLyws1Pa0aNFCWf/pp5/sTcwD2GkIeAdrLXjods46222r+7dVt3PXVbp/PzMyMrQ9wfZ9wK5eAAAAiAjBDwAAwBgEPwAAAEMQ/AAAAAxB8AMAADAEwQ8AAMAQIb6egDtERkYq6zNnztT23Hbbbcq6s23dv/32m7I+Z84cbc+QIUO0Y/7q+eef146lpqYq6506ddL2XH/99cq6PxznAgC4mO5YFBHnx7bouPvYFriOJ34AAACGIPgBAAAYguAHAABgCIIfAACAIQh+AAAAhgiKXb26XbU333yztkf3IcZfffWVtmfEiBHK+qZNm/STCzK6180fP4AdEBGpVEn/822dOnWU9QMHDnhqOj7h7DW48sorlXVnr8Hp06crPCf4B90O3YyMDNvXYuduYOCJHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGCIrjXE6dOqWsFxQUaHtGjx6trOuOhhERKSoqsjcxgzg7zuXMmTNenAlwoeeee0479thjjynrvXv31vYsXLjQ9hyqVaumrNeoUUPbc8MNNyjruuNXRER69uyprMfFxWl7dNf7/PPPtT233nqrdgyBxZVjW7KyspT13NzcCs7GNzIzM23VAx1P/AAAAAxB8AMAADAEwQ8AAMAQBD8AAABDEPwAAAAM4bCcbcf88xc6HJ6eC/zEFVdcoR1bs2aNsu7s2yg2NrbCc/KUcn77exVrzTUNGzZU1letWqXtiYqKUtYPHz6s7XE2plOrVi1lPTo62va1XOHs+/zIkSPK+tSpU7U9o0aNcuscfMWUteZsd6puV6+zHbopKSkVnJH3Ofv+0+1SDtRdvWWtNZ74AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYg+AEAABiC4AcAAGCIEF9PAP5n0KBB2rHatWsr6wUFBZ6aDlBKd2SLiMgnn3yirOuObBEROXv2rLJ+6aWXanuqV6+urFepUkXbo1NYWKgdW7FihbJ+4sQJbc/KlSuV9W+++Ubb8+2332rHEBx0R7Y4ozviBIGPJ34AAACGIPgBAAAYguAHAABgCIIfAACAIQh+AAAAhmBXLy5y++23a8d0H2q+fPlyD80GJtLtxP3yyy+1PXFxccr63r17tT1du3ZV1iMjI7U9+fn5ynrdunW1Pbp1k5eXp+0pKSnRjgEqmZmZtntyc3Nt1QOVs7+PbtezK69nIOCJHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGcFiWZZXrCzXHESBwTZ8+XVm///77tT2//PKLst6tWzdtz5YtW+xNzIvK+e3vVaw1kbCwMGX9k08+0fb06NFDWT937py2R/e9Pnv2bCezgytYa57nymscbK+BjkmvTVl/V574AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYg+AEAABgixNcT8Dfh4eHasaKiIi/OxJ5KldQZ/sknn9T29O3bV1k/e/astmfJkiXKuj/v3EXgOX36tLI+ZswYbU9eXp6y/vDDD2t7dNdjVy+CSW5urq+n4HO8Bv+PJ34AAACGIPgBAAAYguAHAABgCIIfAACAIQh+AAAAhiD4AQAAGCJgjnPp1auXdqx3795uu0+9evW0Y9nZ2cr6F198oe1ZuXJlhedUHrqjWZ577jnb13rqqae0Y6+88ort6yF43H333cr6zJkztT1fffWVsj548GBtz+7du5V13ZEtzsauuOIKbU+/fv2U9csvv1zbs2/fPu0Y4I+Sk5N9PQX4EZ74AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYg+AEAABjC73b1jh49WlkfOXKktueSSy5x2/0dDod2rFmzZsr6E088oe3Ztm2bsv7RRx9pe+bNm6es6z64XkTk2Wef1Y7p6D6g3ls7d6+99lrt2A8//OCVOcCeSZMmKetVq1bV9pw9e1ZZtyzL9v1r1aqlHdPtbL/jjju0PbrdwwcOHLA3McBLMjMzbfdkZWW5fyIBxtnOZtNeH574AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIh1XOMxWcHXPiTufOnVPWnU3ziy++sFV3plIlfRbWfaB769atbd/HlTnoXhtX3X777cr60qVLtT316tVT1jt16qTtefPNN5X1o0ePantq166tHXMnV44U8TRvrTVXfPbZZ8q67ntJRH8M0cmTJ7U9x44dU9ZjYmK0PdWqVVPW8/PztT0PPfSQsr5o0SJtD1zDWnMPV17HlJQU7Vhubm4FZhM4nL1uuuNcXDk6xx+U9T3CEz8AAABDEPwAAAAMQfADAAAwBMEPAADAEAQ/AAAAQ4T4egJ/tWPHDmX96quv1vYkJCQo64cOHbJ9f2e7vFauXKmst2rVyvZ9nHFlZ7MrdDs0161bp+1p0aKF7fv8+uuvyvptt91m+1rwrbvvvltZf/DBB7U9uvVx7bXXanvq1KmjrC9fvlzbo9udOHPmTG3PwYMHtWOAP3K2Czc5OdlWvazrBaKcnBzbPcH2GpSFJ34AAACGIPgBAAAYguAHAABgCIIfAACAIQh+AAAAhiD4AQAAGMLvjnN57LHHlPUXX3xR25OYmKisf/DBB7bv7+w4F3cep3L06FHtmG47+g8//KDtCQsLU9YHDBhgb2IiEh8frx0rKChQ1idPnqztmThxorJ+7NgxW/OC7xUXFyvrb731lrbH2RgAe5YtW6Ydc3ZsSzDJzMzUjuleg5SUFG0Px7kAAAAgKBH8AAAADEHwAwAAMATBDwAAwBAEPwAAAEM4rHJuVXW229Ub4uLitGO63Tr9+/e3fR9XdvWuWbNG27N27VplfcmSJdqe48ePa8fgXu7cqe0uvl5rgCew1jzPlddY9++nP+x01Z1w4Wz3clZWlrLubCdwsCnr+4AnfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGIPgBAAAYImCOcwE8gSMmAO9grXme7siSjIwMt95Hd9SLs2NW3El3BI2IfxxD42sc5wIAAAARIfgBAAAYg+AHAABgCIIfAACAIQh+AAAAhmBXL4zGTkPAO1hrvuNst21OTo73JqLgbBduVlaW7R6wqxcAAAD/h+AHAABgCIIfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiOc4HROGIC8A7WGuAdHOcCAAAAESH4AQAAGIPgBwAAYAiCHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGIPgBAAAYguAHAABgCIIfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGIPgBAAAYguAHAABgCIIfAACAIQh+AAAAhnBYlmX5ehIAAADwPJ74AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGIPgBAAAYguAHAABgCIIfAACAIQh+AAAAhiD4AQAAGILg5yaZmZnicDhK/5yQkCD9+/d36VrJycmSnJzsnokBQYa1BngHay04EfwCwP79+yUzM1Py8vLK3TNhwgRp27atREdHS1hYmDRo0EBGjBghBQUFnpsoEOBcWWsiIqtWrZIOHTrIJZdcInXr1pXhw4dLYWGhZyYJBAG7a+3UqVMyadIkSU1NldjYWImMjJTrr79eJk+eLGfPnvXsZINMiK8nEKy2bt0qlSq5lquXLFlywZ/3798vWVlZkpCQIM2aNSvXNdatWyfNmjWTPn36SGRkpGzevFmmTp0qCxculLy8PImIiHBpboC/8fVay8vLky5dukhiYqL885//lL1798rLL78s27dvl0WLFrk0L8Af+XKt7dy5U4YNGyZdunSRv/3tb1K9enXJzs6WwYMHyzfffCMzZ850aV4mIvh5SNWqVV3uDQ0NrfD9P/3004tq7dq1k169esmCBQukT58+Fb4H4A98vdaeeeYZqVWrluTm5kr16tVF5I9fiQ0aNEiWLFkiqampFb4H4A98udbq1q0rGzdulCZNmpTWHn74YXnwwQdl+vTpMmbMGKlfv36F7mEKftXrghUrVkirVq0kLCxM6tWrJ1OmTLnoa1TvhdiwYYN07txZwsPDJS4uTsaPHy/Tp08Xh8Mhu3btKv26P78XIjc3V1q1aiUiIgMGDBCHwyEOh0NmzJghIn88/t6yZYscOnSozHknJCSIiMixY8fs/pUBn/D3tXb8+HFZunSp9OvXrzT0iYjcf//9Uq1aNfn444/d80IAHubva6127doXhL7zevbsKSIimzdvrsDf3iw88bNp48aNkpqaKtHR0ZKZmSklJSWSkZEhMTExTvv27dsnKSkp4nA4ZNSoURIRESHvvPNOmT9BJSYmyrhx42Ts2LGSnp4uHTt2FBGR9u3bi4jId999JykpKZKRkSGZmZkX9FqWJYcPH5aSkhLZvn27PP3001K5cmXeYIuAEAhrbePGjVJSUiItW7a84FqhoaHSrFkz+f7771382wPeEwhrTefAgQMi8kcwRPkQ/GwaO3asWJYly5cvlyuvvFJERO68805p2rSp074XXnhBjh49KuvXry99P8OAAQOkQYMGTvtiYmLk5ptvlrFjx0q7du2kX79+5Z7rwYMHJTY2tvTPcXFxMmfOHGnUqFG5rwH4SiCstfz8fBGRC9bZebGxsbJ8+fIyrwH4WiCsNZXi4mJ57bXX5Kqrrip9goiy8ateG86ePSvZ2dly++23ly4OkT9+eklLS3Pau3jxYmnXrt0Fb2KNioqSe++9t0JzSk5OFsuylD8VRUVFydKlS2XBggUybtw4qV27NjsNERACZa0VFRWJiPq9T2FhYaXjgL8KlLWmMnToUNm0aZO8+eabEhLCc6zyIvjZUFBQIEVFRcqfZho2bOi0d/fu3co3nnryzaihoaHStWtX6dGjh4wZM0YmTZokDz30kHz++eceuyfgDoGy1sLDw0VE5MyZMxeNnT59unQc8FeBstb+6qWXXpKpU6fKs88+K927d/f4/YIJwc8g7du3l9jYWJk9e7avpwIEhfO/4j3/K98/y8/Pl8suu8zbUwKC3owZM+Spp56SRx55REaPHu3r6QQcgp8N0dHREh4eLtu3b79obOvWrU574+PjZceOHRfVVbW/+vPJ6RV1+vRp+e2339x2PcATAmWtXXvttRISEiJr1669oF5cXCx5eXnlPgsQ8JVAWWvnzZ8/XwYOHCh33HGHTJo0yaVrmI7gZ0PlypUlLS1N5s2bJ3v27Cmtb968WbKzs532pqWlyerVqy84pfzIkSPlevp2/rBl1TEsqm3vJ0+elFOnTl30tZ9++qkcPXr0oh2IgL8JlLVWo0YN6dq1q7z//vty4sSJ0vqsWbOksLBQevfuXeY9AV8KlLUmIvL1119Lnz59pFOnTjJ79myXD5M2ncOyLMvXkwgkGzZskDZt2kidOnVk8ODBUlJSIm+88YbExMTIhg0b5PzLmZCQIMnJyaXnEv3yyy+SlJQkISEhMmzYsNJt72FhYZKXlye7du2S+Ph4EZELzjoSEfn999+lTp06EhMTI08++aRERERImzZt5KqrrpLc3NyLtr3n5eVJ165d5e6775ZGjRpJpUqVZO3atfL+++9LXFycrF27Vi699FJvvmyAbYGw1kRE1q9fL+3bt5fGjRtLenq67N27V1555RXp1KlTmf9wAv4gENba7t275brrrpPi4mJ5+eWXLzg3U0QkKSlJkpKSPP5aBQULti1btsxq0aKFFRoaal199dXWW2+9ZWVkZFh/fjnj4+OtBx544IK+77//3urYsaNVtWpVKy4uznr++eetiRMnWiJiHThwoPTrOnfubHXu3PmC3vnz51uNGze2QkJCLBGxpk+fblmWZeXk5FgiYmVkZJR+bUFBgZWenm41atTIioiIsEJDQ60GDRpYI0aMsAoKCtz9cgAe4+9r7bzly5db7du3t8LCwqzo6GhryJAh1vHjx931MgAe5+9r7XxN9z/VuoQaT/x8bMSIETJlyhQpLCyUypUr+3o6QNBirQHewVrzb/yC3Iv+eqbX4cOHZdasWdKhQwcWB+BGrDXAO1hrgYcTD72oXbt2kpycLImJiXLw4EGZNm2aHD9+XMaMGePrqQFBhbUGeAdrLfAQ/Lyoe/fuMnfuXHn77bfF4XBI8+bNZdq0adKpUydfTw0IKqw1wDtYa4GH9/gBAAAYgvf4AQAAGILgBwAAYAiCHwAAgCHKvbnDnZ8XC/gLf3yLK2sNwYi1BnhHWWuNJ34AAACGIPgBAAAYguAHAABgCIIfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGIPgBAAAYguAHAABgCIIfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGCPH1BHCxG264QVl/5ZVXtD2tW7dW1h0Oh7YnOztbWX/99de1PYsWLdKOAQACS7169ZT1HTt2eOX+27dv144999xzyvrMmTM9NR0j8MQPAADAEAQ/AAAAQxD8AAAADEHwAwAAMATBDwAAwBAOy7Kscn2hk92hpggNDVXWe/bsqe2JiYlR1hMTE7U9d911l7Jes2ZN/eTcyNkuq27duinru3bt8tBsPKuc3/5exVpDMGKt+af33ntPWe/Xr5+XZ3KxkpISZX3z5s3anuuuu85T0wkYZa01nvgBAAAYguAHAABgCIIfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiOc/mLOnXqaMeWLFmirDdt2tStc9iyZYuy/uabb2p7jh07Zvs+qampynrfvn21PR9//LGyft9999m+vz/giAnfGTBggHZs4MCByvpHH32k7cnPz7c9h0OHDinrOTk5tq8F51hr/qlt27bK+tdff63t+fnnn5X1Bg0auGVOZSksLNSOde/eXVlfsWKFp6bjdzjOBQAAACJC8AMAADAGwQ8AAMAQBD8AAABDEPwAAAAMEeLrCfibzp07a8d0u3fPnDmj7Vm8eLGy/o9//EPbo/sA6hMnTmh7XPGvf/1LWb/11lvdeh+YbfLkycp6enq6tke3K61Nmza27+9s56Zu7RYUFNi+z2uvvaYdW7hwobK+bds22/cB3Ok///mPsp6cnKzt2b9/v7IeFxen7dH9e1O7dm395DQ2btyoHTNp966reOIHAABgCIIfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCEcVjk/OduUD7O+/PLLtWNDhgxR1pcvX67tWbRoUYXn5CnDhw9X1l999VVtz5w5c5T1++67zy1z8jY+ON49LrnkEu3Y9u3blfXLLrtM23Pu3LkKz+m8kydPasciIiLcdh9n/7+58n2mO7pGd5RGWWO+xloz26hRo5T1jIwMbU9oaKiyfu+992p7PvjgA3sTC0JlrTWe+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGIPgBAAAYIsTXE/A3+/bt044988wzXpyJ59100022e9avX++BmSDQDRw4UDsWExOjrDvbuXvixAllfcyYMdqe/Px8ZV23q1hEpEGDBtoxHd3fNTIy0vZ9oqKitD3ffPONsl5UVKTtee2115R1Z68b4A0vv/yysn7PPfdoexITE5X133//3S1zMhVP/AAAAAxB8AMAADAEwQ8AAMAQBD8AAABDEPwAAAAMQfADAAAwhMMq5ydn82HWgcnZMQ5Dhw5V1rdt26btue2225T1I0eO2JuYn+CD4+259tprlfUVK1Zoe6pVq6asr1q1Stvz6KOPKus//vijk9n5r2uuuUZZf+6557Q9PXv2VNadfX/ojsEZO3astuedd95R1k+dOqXtcQVrzWwzZ85U1u+77z5tT15enrLevHlzd0wpaJW11njiBwAAYAiCHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIdvXa0Lp1a2W9d+/e2p7p06cr6w0bNtT2tG/fXllPSkqyPTdnHxx/8uRJZf2WW27R9jjbvRmI2Gloz7Rp05T1Bx54wPa1unTpoh1btmyZ7esFouzsbO3Yzp07lfX09HRtjyvfzwkJCcr63r17bV/LGdZa8GvWrJl2LCcnR1n/7bfftD3du3dX1jdt2mRrXqZhVy8AAABEhOAHAABgDIIfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiOc/mLhx9+WDv2xhtvKOuVK1f21HQqzNkHrd95553K+pIlSzw1Hb/DERMXa9SokXbsxx9/tH093dEsN954o+1rmaRFixbKuu5YDBGRiIgI2/dZv369st6qVSvb13KGtRY8Ro4cqayPGjVK21OjRg1l/aWXXtL2PPXUU/YmBhHhOBcAAAD8H4IfAACAIQh+AAAAhiD4AQAAGILgBwAAYAhjd/XWrVtXWd+8ebO2p3r16p6aToV9+eWXyvott9yi7SkpKfHUdAIGOw0v9sorr2jHHnvsMdvXu+mmm5R1Z7tToTd8+HDt2OjRo5X1qKgo2/cJCQmx3eMMay2wNGvWTDu2aNEiZT0mJkbbc+DAAWW9Y8eO2p6ffvpJOwY9dvUCAABARAh+AAAAxiD4AQAAGILgBwAAYAiCHwAAgCEIfgAAAIZw7379AKLbWu7sg8mrVavmqelcIDY2Vll/7733tD1t2rRR1mvXrq3t0b0GgDtt377d11MIKhMnTtSORUdHK+ujRo3y1HQQ4C677DJlfcGCBdoeZ8e26Nxzzz3KOke2eB9P/AAAAAxB8AMAADAEwQ8AAMAQBD8AAABDEPwAAAAMYeyuXp0dO3b4egqSl5enrD/++OPanpkzZyrrXbt21fa8//77tuYFMwwcONDXU4CL2KkPu+rWrausX3755bavtXjxYu3YmjVrbF8PnsETPwAAAEMQ/AAAAAxB8AMAADAEwQ8AAMAQBD8AAABDEPwAAAAMwXEuAcTZh2aXlJQo684+nJ3jXKASGRmpHbMsS1n/z3/+o+357bffKjwn/L+QEP1/trt166asOxwObc+yZcsqPCf4t/r162vHPvroI9vXW7hwobL+0ksvaXtOnTpl+z7wDJ74AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYg+AEAABiCXb0BxNnuyHnz5inrPXr00PY0b95cWV+/fr2teSG47Nu3TzsWGxurrB8+fFjbU1xcXOE5mahFixbK+q233qrtufnmm5V13W5sEZFnn33W3sQQcKZNm6Ydq1evnrJ+5swZbc/LL7+srH/99df2Jgaf4IkfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYIiuNcateurawfOnTIyzPxrEqV9Dk9PDxcWT9+/Li2Z/PmzRWeE4LPxx9/rB177LHHlPWUlBRtT//+/ZX1nJwcbc+2bdu0Y4Gobdu2ynqXLl20PX//+9+V9apVq2p7dMe27N27V9uzYcMG7RgCS3x8vLKuO4bJmZEjR2rHli1bZvt6/qxJkybKeseOHbU9+fn5yvr8+fPdMidP4okfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCECZldvy5YttWNz5sxR1lNTU7U9u3btquiUvK5p06basVtuuUVZ/+abb7Q9RUVFFZ4Tgs/69evder1JkyYp6852nH/44YfK+vbt290yp7I0aNBAO6Zbaw6HQ9tTq1YtZV23G99Vup2GujmLiBw+fNitc4DvFBQUKOtHjx61fS1nu3r379+vrH/22WfannPnzinrXbt21fbUqFFDWe/bt6+2p1mzZtoxHd0JIGfPntX2jBs3zvZ9/AVP/AAAAAxB8AMAADAEwQ8AAMAQBD8AAABDEPwAAAAMQfADAAAwhMPSfar3X7/QyVEF3jBr1izt2D333KOsL1iwQNvzxBNPKOu64xBERE6dOqUdc6ekpCRlfeHChdqemjVrKuu9e/fW9ixevNjWvIJROb/9vcrXa82ZQYMGKesTJkzQ9kRFRSnrzv6e7vz/xZ/v4+y/KS+++KKy/sUXX2h71q1bpx3zNdaa5zVu3FhZd/bf+ri4OLfdf+3atdox3XEuTZo00fZERERUeE7lMWXKFGX973//u7anuLhYWS8sLHTLnCqirLXGEz8AAABDEPwAAAAMQfADAAAwBMEPAADAEAQ/AAAAQwTFrl5nH9hs14YNG7RjR44cUdadfXD8smXLlHXd7isRkYceekhZ1+2OFBHJyMhQ1l944QVtD9hp6C7Odga2bdtWWX/88ce1PbodgK6oVEn/86077/P666/b7tm7d6927JtvvqnIdPwOa813+vfvrx179913vTcRm/bs2aOs606xEBE5ffq0sl6nTh1tT+vWrZV1Z7uU/Rm7egEAACAiBD8AAABjEPwAAAAMQfADAAAwBMEPAADAEAQ/AAAAQwTMcS6hoaHasX/84x/K+oMPPqjtiYyMrPCcPEX3QevTpk3T9ug+ZBrOccQE4B2sNd+Jjo7WjumOenH3UWBnzpxR1jdu3Kjt6d27t7KekJCg7Tl8+LCy3rJlS23P7NmzlfXff/9d2+PPOM4FAAAAIkLwAwAAMAbBDwAAwBAEPwAAAEMQ/AAAAAwRMLt6XXHNNddox2677TZlXbdD2FUrV65U1p9//nltz5o1a5T1Q4cOuWVO+H/sNAS8g7Xmn2rWrKmsDxw4UNuTlpamrJ8+fVrbM2fOHGV99erV2h7d98zu3bu1PWBXLwAAAP4PwQ8AAMAQBD8AAABDEPwAAAAMQfADAAAwBMEPAADAEEF9nAtQFo6YALyDtQZ4B8e5AAAAQEQIfgAAAMYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGIPgBAAAYguAHAABgCIIfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGIPgBAAAYguAHAABgCIIfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCEclmVZvp4EAAAAPI8nfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGIPgBAAAYguAHAABgCIIfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYg+LlJZmamOByO0j8nJCRI//79XbpWcnKyJCcnu2diQJBhrQHewVoLTgS/ALB//37JzMyUvLw8W33FxcUyYcIEadSokYSFhUlMTIzccsstsnfvXs9MFAhwdtfarl27xOFwaP83aNAgz04YCFCu/Ls2YcIEadu2rURHR0tYWJg0aNBARowYIQUFBZ6baBAK8fUEgtXWrVulUiXXcvWSJUsu+PP+/fslKytLEhISpFmzZuW6xu+//y633HKLrFq1SgYNGiRJSUly9OhR+fbbb+W3336TuLg4l+YG+BtfrrXo6GiZNWvWRfXFixfL7NmzJTU11aV5Af7I1/+urVu3Tpo1ayZ9+vSRyMhI2bx5s0ydOlUWLlwoeXl5EhER4dLcTEPw85CqVau63BsaGlrh+7/66quybNkyWbFihbRu3brC1wP8lS/XWkREhPTr1++i+owZM6R69epy6623Vuj6gD/x9b9rn3766UW1du3aSa9evWTBggXSp0+fCt/DBPyq1wUrVqyQVq1aSVhYmNSrV0+mTJly0deo3guxYcMG6dy5s4SHh0tcXJyMHz9epk+fLg6HQ3bt2lX6dX9+L0Rubq60atVKREQGDBhQ+iukGTNmiIjIqVOnZMuWLXLo0KHS/nPnzsnrr78uPXv2lNatW0tJSYmcOnXKra8B4A3+vtZU8vPzJScnR+644w4JCwtz+e8OeFMgrrXzcxIROXbsmN2/srF44mfTxo0bJTU1VaKjoyUzM1NKSkokIyNDYmJinPbt27dPUlJSxOFwyKhRoyQiIkLeeeedMn+CSkxMlHHjxsnYsWMlPT1dOnbsKCIi7du3FxGR7777TlJSUiQjI0MyMzNFRGTTpk2yf/9+SUpKkvT0dJk5c6YUFxdL06ZN5fXXX5eUlJSKvxCAhwXCWlP58MMP5dy5c3Lvvffa+wsDPhJIa82yLDl8+LCUlJTI9u3b5emnn5bKlSuzccQGgp9NY8eOFcuyZPny5XLllVeKiMidd94pTZs2ddr3wgsvyNGjR2X9+vWl72cYMGCANGjQwGlfTEyM3HzzzTJ27Fhp166d8tdKf7V9+3YR+ePXvVFRUaU/uU2YMEG6desma9askaSkpDKvA/hSIKw1ldmzZ0tsbKzceOONLvUD3hZIa+3gwYMSGxtb+ue4uDiZM2eONGrUqNzXMB2/6rXh7Nmzkp2dLbfffnvp4hD546eXtLQ0p72LFy+Wdu3aXfAm1qioqAo/FUhOThbLsi74qaiwsFBERE6cOCFfffWV9O/fX/r37y9ffvmlWJYlL774YoXuCXhaoKy1v9q2bZusW7dO+vTp4/Kb4AFvCrS1FhUVJUuXLpUFCxbIuHHjpHbt2qX/5qF8+C+TDQUFBVJUVKT8aaZhw4ZOe3fv3i3169e/qK6qVVR4eLiIiNxwww1yxRVXlNavvPJK6dChg6xatcrt9wTcKVDW2l/Nnj1bRIRf8yJgBNpaCw0Nla5du0qPHj1kzJgxMmnSJHnooYfk888/99g9gw3BLwhddtllIiLK92fUqVNHjh496u0pAUaYM2eONGzYUFq0aOHrqQBGaN++vcTGxpb+0IWyEfxsiI6OlvDw8NL30P3Z1q1bnfbGx8fLjh07Lqqran/155PTy6Np06ZSpUoV2bdv30Vj+/fvl+joaFvXA7wtUNban3377beyY8cOnvYhoATiWvur06dPy2+//ea26wU7gp8NlStXlrS0NJk3b57s2bOntL5582bJzs522puWliarV6++4JTyI0eOlOunlPOHUqq2q6u2vUdGRkr37t1l1apVsmXLlgvmuWrVKrnpppvKvCfgS4Gy1v5szpw5IiLSt2/fMu8D+ItAWWsnT55UHkv26aefytGjR6Vly5Zl3hN/cFiWZfl6EoFkw4YN0qZNG6lTp44MHjxYSkpK5I033pCYmBjZsGGDnH85ExISJDk5ufRcol9++UWSkpIkJCREhg0bVrrtPSwsTPLy8mTXrl0SHx8vInLBWUcif3wKR506dSQmJkaefPJJiYiIkDZt2shVV10lubm5ym3vmzZtkjZt2khkZKQMHz5cREQmTpwoJSUl8v3338vll1/uldcLcFWgrDWRP94gf/nll8tVV10lq1ev9sbLA7hNIKy1vLw86dq1q9x9993SqFEjqVSpkqxdu1bef/99iYuLk7Vr18qll17qzZctYPHEz6akpCTJzs6W6OhoGTt2rLz77ruSlZUlPXv2dNp3xRVXSE5OjiQmJsqECRPktddekwceeEAefPBBERGnB71WqVJFZs6cKZUrV5ZHHnlE7rnnHlm2bJnT+zVu3FiWLVsmTZo0kfHjx8uECROkdevWsnLlSkIfAkKgrDURkS+//FIOHjzI0z4EpEBYa3FxcXLnnXfKv//9bxk1apT87W9/k5UrV8rQoUNlzZo1hD4beOLnYyNGjJApU6ZIYWGhVK5c2dfTAYIWaw3wDtaaf+OJnxcVFRVd8OfDhw/LrFmzpEOHDiwOwI1Ya4B3sNYCD5/c4UXt2rWT5ORkSUxMlIMHD8q0adPk+PHjMmbMGF9PDQgqrDXAO1hrgYfg50Xdu3eXuXPnyttvvy0Oh0OaN28u06ZNk06dOvl6akBQYa0B3sFaCzy8xw8AAMAQvMcPAADAEAQ/AAAAQxD8AAAADFHuzR3u/Fw9wF/441tcWWsIRqw1wDvKWms88QMAADAEwQ8AAMAQBD8AAABDEPwAAAAMQfADAAAwBMEPAADAEAQ/AAAAQxD8AAAADEHwAwAAMATBDwAAwBAEPwAAAEOU+7N64d+eeOIJZT0rK0vbU6VKFWU9LS1N25OTk2NvYgAAwG/wxA8AAMAQBD8AAABDEPwAAAAMQfADAAAwBMEPAADAEA7LsqxyfaHD4em5oAxxcXHasdzcXGX96quvtn2fX375RTsWHx9v+3r+rJzf/l7FWkMwYq0B3lHWWuOJHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGCPH1BHCxRo0aKesrVqzQ9kRFRbnt/p999pnbrgUAAPwHT/wAAAAMQfADAAAwBMEPAADAEAQ/AAAAQxD8AAAADMGuXj/UqlUrZd2Vnbtz587Vjr399tvKemFhoe37AACCR5UqVbRjI0eOVNbHjx+v7XnvvfeU9T179tibWBk2bNigrDs7raKkpMStc/B3PPEDAAAwBMEPAADAEAQ/AAAAQxD8AAAADEHwAwAAMATBDwAAwBAOy7Kscn2hw+HpuRilR48e2rHZs2cr65GRkbbv8/DDD2vH3n33XWW9Vq1a2p5Dhw7ZnoM/K+e3v1ex1hCMWGv+qXLlysr6vHnztD233HKLh2bjObpjXkREOnbsqKyfOHHCU9PxqLLWGk/8AAAADEHwAwAAMATBDwAAwBAEPwAAAEMQ/AAAAAwR4usJBLtu3bop6x988IG2JyIiwvZ9unTpoqx//fXX2p6zZ88q68G2cxewq169etqxhIQEZb1Tp07anvj4eGW9atWq2p4+ffoo648++qi256233tKOASo1a9ZU1qOiorQ9R44csX2f5cuXK+vOdgiHhLgvoiQlJWnHevbsqay/9957bru/P+GJHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACG4DgXNwgPD9eO/c///I+y7so29ZKSEu1Yfn6+sq47sgXwZ5GRkcp6bGys7WulpqZqx3r16qWsN2vWTNtz7NgxZf306dPaHt2xLbpjXkT0H7S+fv16bQ9g1+HDh5X1G264wSv31x2lIiJSt25dZX306NHaHlf+G9GmTRtlneNcAAAAENAIfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAh2NXrBhkZGdoxV3bv/vzzz8p6x44dtT379++3fR/Arvr16yvrO3bs0PZUqqT++bJfv37anmeeeUZZv+aaa7Q9ut2Jn3zyibbn6aef1o7p/Pjjj8r6iRMntD133XWXsv7hhx9qeyZPnqysr1271snsgMDy2WefaccuueQSZX3EiBFuncOCBQvcej1/xxM/AAAAQxD8AAAADEHwAwAAMATBDwAAwBAEPwAAAEMQ/AAAAAzBcS42REVFKevDhw936302bNigrHNkC3xNd2xLTEyMtkd3ZMpjjz2m7fnuu++U9TFjxmh7Jk6cqKw7O2bFW0aOHGm754svvlDWz507V9HpAH4jIiJCOzZt2jRlvUGDBrbv4+zYmGXLltm+XiDjiR8AAIAhCH4AAACGIPgBAAAYguAHAABgCIIfAACAIdjVa8OTTz6prIeFhdm+VlFRkXbs5Zdftn29Fi1aKOudOnXS9nTo0EFZf/XVV7U9W7duVdYLCgqczA7BIjw8XFnftm2bticyMlJZ1+1eFxHp27evsr5z504ns/OtJk2aaMcaN26srOt2SYuILF26tMJzArzJ2Q7dzMxMZb1NmzbaHt2/Uc58+umnynr//v21Pc7+PQ5GPPEDAAAwBMEPAADAEAQ/AAAAQxD8AAAADEHwAwAAMATBDwAAwBAc5/IXcXFx2rGBAwe67T5ffvmldmzLli3K+kcffaTt6dGjh7KuO37DmZ49e2rHVqxYoaz36tVL2/Prr7/angP8k8PhUNZ1R7aI6I8s6d69u7Zn//799ibmRVWqVFHW33jjDW2P7sin9PR0bU9xcbG9iQFe0rlzZ2X92Wef1fa4cjSLzty5c7VjDz74oLJ+8uRJt90/0PHEDwAAwBAEPwAAAEMQ/AAAAAxB8AMAADAEwQ8AAMAQDsuyrHJ9oWY3X7D56quvtGMpKSm2r3f69Gllfdy4cdqerl27Kus33nijtkf3/085/++tMGe7rO666y6vzMEV3np97PDntVa5cmVlvVu3btqepUuXKuuBumu1cePGyvoPP/yg7dm5c6ey3rx5c23P8ePH7U3Mz7HWAsvo0aO1Y8OGDVPWo6Ojbd/n2LFj2rH58+cr68OHD9f2nDhxwvYcgk1Za40nfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGIPgBAAAYIsTXE/A3l156qe2e33//XTumO/rh448/1va0bNnS9hx027enTJmi7SkpKVHWhwwZYvv+rrxuCDxnz55V1hcuXOjlmXhWTEyMdiw7O9v29fr376+sB9uRLQgetWvX1o65cmyLzgsvvODSGFzHEz8AAABDEPwAAAAMQfADAAAwBMEPAADAEAQ/AAAAQxi7q7dHjx7KelJSklvvM3ToUGXd2c7dc+fOKetTp07V9mRlZSnrBw8e1PbUqlVLWXdlV29xcbHtHsBfDR48WDt2+eWXK+uvv/66tmf16tUVnhPgTW+++aZ2rG/fvsq6s53AOj179tSOTZ48WVlnN3zF8MQPAADAEAQ/AAAAQxD8AAAADEHwAwAAMATBDwAAwBAEPwAAAEM4LMuyyvWFDoen5+J2VatW1Y7l5OQo623btrV9n+XLl2vH1q1bp6yPGDFC27Ny5UplPS0tTduj20bfqlUrbc/TTz+trDs7ambv3r3K+g033KDt2bNnj3bM18r57e9VgbjWAlXz5s2Vdd0adCY+Pl479uuvv9q+XrBhrQWPLl26KOsffPCBtseVo17mzp2rrK9YsULbM3HiRNv3CTZlrTWe+AEAABiC4AcAAGAIgh8AAIAhCH4AAACGIPgBAAAYIsTXE/Ck6667Tjvmyu5dHWc7WmNiYmxfr2HDhsr6okWLtD0dO3a0fR8dZzuCIiIilPWaNWtqe/x5Vy/MlpiYqKw7OxEgKytLWWfnLkzx1VdfKetDhw7V9nz44Ye279OrVy9lfcqUKbavhf/HEz8AAABDEPwAAAAMQfADAAAwBMEPAADAEAQ/AAAAQxD8AAAADOGwyvnJ2YH4YdaNGjXSjq1atUpZd3YsCURycnKU9bvvvlvbc+jQIU9Np8L44Pjg17x5c+3YsmXLlPWDBw9qe5o0aaKsnzlzxt7EDMNaC366475ERHJzc5X1Fi1a2L5P06ZNtWM//vij7esFm7LWGk/8AAAADEHwAwAAMATBDwAAwBAEPwAAAEMQ/AAAAAwR4usJeNKWLVu0Y/fee6+yPmfOHG1PjRo1Kjwnf5KXl6esp6ena3t+/vlnZf3w4cPumBLgskqV1D/H9u7dW9sTHh6urP/rX//S9rB7F1A7efKkduzUqVNenAmc4YkfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYI6uNcnFm0aJGynpSUpO2ZMmWKst6tWze3zMkTfvjhB+3YmDFjlPW1a9d6ajqAx/Tt21dZf+qpp7Q9//73v5X1kSNHumVOgEliY2O1Y3Xr1vXiTOAMT/wAAAAMQfADAAAwBMEPAADAEAQ/AAAAQxD8AAAADGHsrl6dX375RTs2fvx4Zb1Lly7anipVqlR4TufNnj1bO5adna2sO/uweT40G4EmIiJCO6bb1XvkyBFtzxNPPFHhOQH+IjIyUlnv16+fW++jW2uJiYnanqioKNv3+fnnn5V1Z2saZeOJHwAAgCEIfgAAAIYg+AEAABiC4AcAAGAIgh8AAIAhCH4AAACG4DgXG1atWqWsV61a1cszAcz0zDPPaMe6deumrL/99tvanry8vIpOCfAI3fEn27dv1/ZUqqR+llOjRg23zMkTdEe2iIikpaUp6/n5+Z6ajhF44gcAAGAIgh8AAIAhCH4AAACGIPgBAAAYguAHAABgCIdlWVa5vtDh8PRcAK8r57e/V7HW9LZu3aodu+yyy5T1du3aaXt++OGHCs8J5cNas+fSSy9V1gsKCrw8k/L75ZdftGMffPCBsj516lRtz08//VThOZmorLXGEz8AAABDEPwAAAAMQfADAAAwBMEPAADAEAQ/AAAAQxD8AAAADBHi6wkAMFNCQoJ2LDs7W1mvX7++tueFF15Q1jmyBYGoqKhIWV+3bp22p0WLFsr6/PnztT0bN25U1j/++GNtj+5YJWfHiJSUlGjH4F088QMAADAEwQ8AAMAQBD8AAABDEPwAAAAMQfADAAAwhMMq5ydn+/OHWQOu4oPjfefrr7/WjnXo0EFZX7RokbZnyJAhyvquXbtszQuewVoDvKOstcYTPwAAAEMQ/AAAAAxB8AMAADAEwQ8AAMAQBD8AAABDEPwAAAAMEeLrCQAw06+//qod0x3B8uijj2p79uzZU9EpAUDQ44kfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCEcVjk/OZsPs0Yw4oPjAe9grQHeUdZa44kfAACAIQh+AAAAhiD4AQAAGILgBwAAYAiCHwAAgCEIfgAAAIYo93EuAAAACGw88QMAADAEwQ8AAMAQBD8AAABDEPwAAAAMQfADAAAwBMEPAADAEAQ/AAAAQxD8AAAADEHwAwAAMMT/Aspq1S23o6TrAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing your data for training with DataLoaders"
      ],
      "metadata": {
        "id": "PuuzJ8yMMFfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=4, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "XfdwASa7MF6E"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iterate through the DataLoader"
      ],
      "metadata": {
        "id": "y83tdLkdMJaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "sBRf--4qMJwV",
        "outputId": "7fcdcdfc-6565-4af4-83c1-5729267346e4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([4, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([4])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the network"
      ],
      "metadata": {
        "id": "0Z48WsakMQh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2): # loop over the dataset multiple times\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(torch.flatten(inputs,1))\n",
        "    iteration_loss = loss(outputs, labels)\n",
        "    iteration_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += iteration_loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "      running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0G9HHPaMRL1",
        "outputId": "9943fc86-1244-4599-98b5-83a3c66f6446"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.285\n",
            "[1,  4000] loss: 2.209\n",
            "[1,  6000] loss: 1.993\n",
            "[1,  8000] loss: 1.502\n",
            "[1, 10000] loss: 1.004\n",
            "[1, 12000] loss: 0.776\n",
            "[1, 14000] loss: 0.631\n",
            "[2,  2000] loss: 0.533\n",
            "[2,  4000] loss: 0.483\n",
            "[2,  6000] loss: 0.459\n",
            "[2,  8000] loss: 0.427\n",
            "[2, 10000] loss: 0.418\n",
            "[2, 12000] loss: 0.400\n",
            "[2, 14000] loss: 0.396\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4: What is the meaning of epoch, forward pass, backward pass. What is the effect of torch.flatten(inputs, 1), and optimizer.step()?"
      ],
      "metadata": {
        "id": "sCr_DQzYMkR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch: An epoch is a single pass through the entire training dataset. The outer loop for epoch in range(2) indicates that the training process will loop over the dataset two times.\n",
        "\n",
        "Forward Pass: The forward pass is the process of passing input data through the neural network to compute the predicted outputs. In this code, outputs = net(torch.flatten(inputs, 1)) represents the forward pass, where inputs are passed through the neural network (net) after being flattened along the second dimension using torch.flatten(inputs, 1).\n",
        "\n",
        "Backward Pass: The backward pass, also known as backpropagation, is the process of computing gradients of the loss function with respect to the network's parameters. This is done using the backward() method: iteration_loss.backward(). It computes gradients for all the tensors used to compute iteration_loss.\n",
        "\n",
        "Optimizer: optimizer.step() updates the parameters of the neural network using the computed gradients and the optimization algorithm (e.g., SGD, Adam) to minimize the loss. It adjusts the network's weights and biases based on the computed gradients and the specified optimization strategy.\n",
        "\n",
        "torch.flatten(inputs, 1): This function reshapes the input tensor inputs to have a flattened shape along the second dimension (dimension 1). It's likely used to prepare the input data for the neural network if it expects a flattened representation."
      ],
      "metadata": {
        "id": "7Ax-2OHqMrRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './my_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "GFzBSh2bMw_8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the network on the test data"
      ],
      "metadata": {
        "id": "zKj_JG5DM3Fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzZiaiY7M308",
        "outputId": "4ded0aec-332c-40f4-8276-80d9ec69ab48"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "  for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    # calculate outputs by running images through the network\n",
        "    outputs = net(torch.flatten(images,1))\n",
        "    # the class with the highest energy is what we choose as prediction\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct// total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3D0jabyM8B8",
        "outputId": "f1753d7d-984c-4481-a566-a76a2ac7b620"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 11 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5: Train the network in the previous example, but instead of using 2 hidden layers, try 3 hidden layers."
      ],
      "metadata": {
        "id": "DSYKpAOVNA64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Assuming net is the previously defined neural network with 2 hidden layers\n",
        "\n",
        "class ThreeHiddenLayerNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ThreeHiddenLayerNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 64)  # First hidden layer\n",
        "        self.fc2 = nn.Linear(64, 64)   # Second hidden layer\n",
        "        self.fc3 = nn.Linear(64, 64)   # Third hidden layer\n",
        "        self.fc4 = nn.Linear(64, 10)   # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.relu(self.fc1(x))   # ReLU activation for first hidden layer\n",
        "        x = torch.relu(self.fc2(x))   # ReLU activation for second hidden layer\n",
        "        x = torch.relu(self.fc3(x))   # ReLU activation for third hidden layer\n",
        "        x = self.fc4(x)               # Output layer without activation (for example, using CrossEntropyLoss)"
      ],
      "metadata": {
        "id": "Dl9E55b8M_us"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data loaders\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "fTDbFPNxP_Tr"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the neural network model\n",
        "class ThreeHiddenLayerNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ThreeHiddenLayerNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)  # Example for MNIST dataset, 28*28 = 784 input features\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)    # Output layer for 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the network\n",
        "net = ThreeHiddenLayerNet()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
        "\n",
        "# Training the network\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = torch.flatten(inputs, start_dim=1)  # Flatten the images\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        iteration_loss = loss(outputs, labels)\n",
        "        iteration_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += iteration_loss.item()\n",
        "        if i % 200 == 199:  # print every 200 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Testing the network\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        images, labels = data\n",
        "        images = torch.flatten(images, start_dim=1)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDenlldNOBqU",
        "outputId": "67db4359-c247-4b3e-b1b3-880b184fb884"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   200] loss: 2.295\n",
            "[1,   400] loss: 2.290\n",
            "[1,   600] loss: 2.283\n",
            "[1,   800] loss: 2.275\n",
            "[2,   200] loss: 2.261\n",
            "[2,   400] loss: 2.250\n",
            "[2,   600] loss: 2.239\n",
            "[2,   800] loss: 2.224\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 32 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 6: Train the network in the previous example using Adam optimizer"
      ],
      "metadata": {
        "id": "P24qPC9-QcfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the network\n",
        "net = ThreeHiddenLayerNet()\n",
        "\n",
        "# Use Adam optimizer with a learning rate of 0.001\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# Assuming train_dataloader contains your training dataset\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        iteration_loss = loss(outputs, labels)\n",
        "        iteration_loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += iteration_loss.item()\n",
        "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "  for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    # calculate outputs by running images through the network\n",
        "    outputs = net(torch.flatten(images,1))\n",
        "    # the class with the highest energy is what we choose as prediction\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct// total} %')"
      ],
      "metadata": {
        "id": "SwC28BWXgDOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training on GPU"
      ],
      "metadata": {
        "id": "RoeGWOZPRwNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H96023HlRwlZ",
        "outputId": "3e11f9c4-acb8-4722-c471-d27c64804724"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "\n",
        "net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTYskKP0R1DE",
        "outputId": "1c0543fb-6bc3-4a1b-a733-a4b492467dc1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 7: Train the network in the previous example on GPU. Do you notice significant speedup? if not, try to increase the size of your network."
      ],
      "metadata": {
        "id": "-LyjoD8hR4g0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we try on small network."
      ],
      "metadata": {
        "id": "bh-XgBqaST3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(2): # loop over the dataset multiple times\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(torch.flatten(inputs,1))\n",
        "    iteration_loss = loss(outputs, labels)\n",
        "    iteration_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += iteration_loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "      running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGq7HldtR43M",
        "outputId": "2e4d0643-b297-4922-813a-eadfc0806b8f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CPU time: 46s\n",
        "\n",
        "GPU time: 56s\n",
        "\n",
        "We can't see the speedup, even CPU is faster. So, we will increase the size of the network as follows:"
      ],
      "metadata": {
        "id": "WUUV3VysSIlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LargerThreeHiddenLayerNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LargerThreeHiddenLayerNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)  # First hidden layer with 128 neurons\n",
        "        self.fc2 = nn.Linear(512, 512)  # Second hidden layer with 128 neurons\n",
        "        self.fc3 = nn.Linear(512, 10)   # Output layer with 10 neurons\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.relu(self.fc1(x))   # ReLU activation for first hidden layer\n",
        "        x = torch.relu(self.fc2(x))   # ReLU activation for second hidden layer\n",
        "        x = self.fc3(x)               # Output layer without activation (for example, using CrossEntropyLoss)\n",
        "        return x"
      ],
      "metadata": {
        "id": "oBpCBZTfSJI7"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Assuming net is the previously defined neural network with 3 hidden layers\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {device}\")\n",
        "\n",
        "# Initialize the larger network and move it to the device (GPU if available)\n",
        "net = LargerThreeHiddenLayerNet().to(device)\n",
        "\n",
        "# Define the loss function\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use Adam optimizer with a learning rate of 0.001\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# Assuming train_dataloader contains your training dataset\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        inputs, labels = data\n",
        "        # Move the inputs and labels to the device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        iteration_loss = loss(outputs, labels)\n",
        "        iteration_loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += iteration_loss.item()\n",
        "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr12_59OSNNk",
        "outputId": "c38de079-a102-48ac-93bd-4df9c13962c6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU time: 1m 17s\n",
        "\n",
        "CPU time: 7m 28s\n",
        "\n",
        "Now, we can see the huge difference between the run on CPU and GPU"
      ],
      "metadata": {
        "id": "cvQGuOTqSQa7"
      }
    }
  ]
}